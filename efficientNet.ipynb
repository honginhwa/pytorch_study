{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "efficientNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aUoGsgTaSQUbBNPmCfN75vEdM17cPCWm",
      "authorship_tag": "ABX9TyM+Onpp6yF2hwb5yCy2CIiM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/honginhwa/pytorch_study/blob/master/efficientNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGapWzbURio8",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOq_50l1p_LS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "f4008a9f-2a05-47ac-d543-d0825e174b51"
      },
      "source": [
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "#model = EfficientNet.from_name('efficientnet-b0')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/83/f9c5f44060f996279e474185ebcbd8dbd91179593bffb9abe3afa55d085b/efficientnet_pytorch-0.7.0.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-cp36-none-any.whl size=16031 sha256=83edc14e693d26103ad63c4d66b95ac3115fc539f10154df060dee0b29222bb4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmrLHvVatG2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6f47bf68-c6fa-4c39-fa2e-a9c7d4094907"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "#from torchvision import transforms\n",
        "\n",
        "import cv2\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random as rand\n",
        "from random import *\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "model_name = 'efficientnet-b0'  # b5\n",
        "\n",
        "image_size = EfficientNet.get_image_size(model_name)\n",
        "print(image_size)\n",
        "model = EfficientNet.from_name(model_name, num_classes=7)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRjS53sLuEoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "}\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    \n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPh50YRQF3PZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"/content/drive/My Drive/Colab Notebooks/Labeld_Crop_Data\"\n",
        "trDsets = {x: dset.ImageFolder(os.path.join(data_dir, x), train_transforms[x]) for x in ['train', 'val']}\n",
        "trLoaders = {x: torch.utils.data.DataLoader(trDsets[x], batch_size=5, shuffle=True, num_workers=4) for x in ['train', 'val']}  \n",
        "\n",
        "teDsets = dset.ImageFolder(os.path.join(data_dir,'test'), transform=test_transforms)\n",
        "teLoaders = torch.utils.data.DataLoader(teDsets, batch_size=5, shuffle=False, num_workers=4)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4w1nKYfGkEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "328f5e09-1ae5-46aa-8862-a60c723680a6"
      },
      "source": [
        "print(trDsets['train'].classes)\n",
        "print(teDsets.classes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '3', '4', '5', '6', '7', '8', '9']\n",
            "['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '3', '4', '5', '6', '7', '8', '9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9eCcrRnuYq8",
        "colab_type": "text"
      },
      "source": [
        "## data split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZGQCWW9uIhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "6e24b646-8431-48b1-e806-f2f4a8f8e977"
      },
      "source": [
        "trDsets_sizes = {x: len(trDsets[x]) for x in ['train', 'val']}\n",
        "print(trDsets_sizes)\n",
        "class_names = trDsets['train'].classes\n",
        "print(class_names)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'train': 9936, 'val': 2503}\n",
            "['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '3', '4', '5', '6', '7', '8', '9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KaMfZ3gvwMd",
        "colab_type": "text"
      },
      "source": [
        "## data loader 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MojpnUIufdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "0f072be9-6273-42e8-952e-2af626ebc7c3"
      },
      "source": [
        "print(torch.cuda.is_available())     # GPU 사용 가능 여부\n",
        "print(torch.cuda.current_device())   # GPU 디바이스의 위치\n",
        "print(torch.cuda.device_count())     # 사용가능한 GPU 개수\n",
        "print(torch.cuda.get_device_name(0)) # GPU의 이름\n",
        "print(torch.cuda.device(0))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "0\n",
            "1\n",
            "Tesla T4\n",
            "<torch.cuda.device object at 0x7f12c9948f98>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV_byAE8Gy-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0X-J5iiHrGP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16b119a7-c70d-43a1-fdeb-4323a0be0a92"
      },
      "source": [
        "model = EfficientNet.from_name('efficientnet-b0')\n",
        "num_ftrs = model._fc.in_features\n",
        "print(num_ftrs)\n",
        "model.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1280\n",
            "EfficientNet(\n",
            "  (_conv_stem): Conv2dStaticSamePadding(\n",
            "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
            "    (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "  )\n",
            "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "  (_blocks): ModuleList(\n",
            "    (0): MBConvBlock(\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (1): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (2): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (3): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (4): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (5): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (6): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (7): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (8): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (9): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (10): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (11): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (12): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (13): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (14): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "    (15): MBConvBlock(\n",
            "      (_expand_conv): Conv2dStaticSamePadding(\n",
            "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
            "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
            "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
            "      )\n",
            "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_se_reduce): Conv2dStaticSamePadding(\n",
            "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_se_expand): Conv2dStaticSamePadding(\n",
            "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_project_conv): Conv2dStaticSamePadding(\n",
            "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "        (static_padding): Identity()\n",
            "      )\n",
            "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "      (_swish): MemoryEfficientSwish()\n",
            "    )\n",
            "  )\n",
            "  (_conv_head): Conv2dStaticSamePadding(\n",
            "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "    (static_padding): Identity()\n",
            "  )\n",
            "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
            "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
            "  (_dropout): Dropout(p=0.2, inplace=False)\n",
            "  (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
            "  (_swish): MemoryEfficientSwish()\n",
            "  (fc): Linear(in_features=1280, out_features=22, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g9MSPODHV8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6765fbc1-f4bb-42d7-b49f-cb8fcf707959"
      },
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.SGD(model.parameters(), \n",
        "                         lr = 0.05,\n",
        "                         momentum=0.9,\n",
        "                         weight_decay=1e-4)\n",
        "\n",
        "lmbda = lambda epoch: 0.98739\n",
        "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)\n",
        "\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, factor=0.1, patience=5)\n",
        "'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ncriterion = nn.CrossEntropyLoss()\\noptimizer_ft = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\\nexp_lr_scheduler = lr_scheduler.ReduceLROnPlateau(optimizer_ft, factor=0.1, patience=5)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyLOZQZm_G_-",
        "colab_type": "text"
      },
      "source": [
        "## 데이타 체크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aCZx8ABEYwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=8):\n",
        "    \n",
        "    global_info = []\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict()) # state_dict() = 모델 불러오기 \n",
        "    best_acc = 0.0\n",
        "    early_stopping = EarlyStopping(patience=11, verbose=True)  # EarlyStopping = 11번에 큰 변화가 없다면 학습을 그만한다.\n",
        "    for epoch in range(num_epochs):\n",
        "        local_info = []\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)                                            #train 시작\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()                                   # list에 train이면 학습 val이면 평가 \n",
        "            else:\n",
        "                model.eval()                              \n",
        "                \n",
        " #               if epoch > 0:\n",
        " #                   scheduler.step(val_loss)\n",
        "                    \n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in trLoaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()                              # 가중치 변화도 = 0 >> forward \n",
        "\n",
        "                # forward\n",
        "                # tensor는 인풋값이 디폴트는 그래디언트가 안들어가있는데 이 값을  \n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)                              # torch.max(output,1)은 아웃풋이 [0.1, 0.2, 0.9]일때 (0.9[값] ,2[인덱스])가 나온다 \n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()                              # backward로 최신화로 스텝으로 가자 \n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)          # item() = tensor값을 scalar값으로 표기 * input.size(0)      \n",
        "            \n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / trDsets_sizes[phase]\n",
        "            if phase == 'val':\n",
        "                val_loss = running_loss / trDsets_sizes['val']\n",
        "            epoch_acc = running_corrects.double() / trDsets_sizes[phase]\n",
        "\n",
        "            if phase == 'train':\n",
        "                local_info.append(epoch_loss)\n",
        "                ea = epoch_acc.cpu().numpy()\n",
        "                local_info.append(ea)\n",
        "            else:\n",
        "                local_info.append(epoch_loss)\n",
        "                ea = epoch_acc.cpu().numpy()\n",
        "                local_info.append(ea)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        " \n",
        "        lr_get = get_lr(optimizer)\n",
        "        print(\"Current learning rate : {:.8f}\".format(lr_get))\n",
        "        global_info.append(local_info)\n",
        "        \n",
        "        if phase =='val':\n",
        "            early_stopping(epoch_loss, model)\n",
        "\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "    \n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "        \n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpW-bFFOEsN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "864d87ff-1d9b-4b69-8b5d-6843c7aed068"
      },
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n",
        "model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=100)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/99\n",
            "----------\n",
            "train Loss: 2.3311 Acc: 0.2503\n",
            "val Loss: 1.6823 Acc: 0.4515\n",
            "Current learning rate : 0.05000000\n",
            "Validation loss decreased (inf --> 1.682295).  Saving model ...\n",
            "Epoch 1/99\n",
            "----------\n",
            "train Loss: 1.5340 Acc: 0.5072\n",
            "val Loss: 0.7213 Acc: 0.7691\n",
            "Current learning rate : 0.05000000\n",
            "Validation loss decreased (1.682295 --> 0.721258).  Saving model ...\n",
            "Epoch 2/99\n",
            "----------\n",
            "train Loss: 1.0066 Acc: 0.6868\n",
            "val Loss: 0.8068 Acc: 0.7835\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 1 out of 11\n",
            "Epoch 3/99\n",
            "----------\n",
            "train Loss: 0.7387 Acc: 0.7664\n",
            "val Loss: 0.4451 Acc: 0.8618\n",
            "Current learning rate : 0.05000000\n",
            "Validation loss decreased (0.721258 --> 0.445124).  Saving model ...\n",
            "Epoch 4/99\n",
            "----------\n",
            "train Loss: 0.5904 Acc: 0.8162\n",
            "val Loss: 0.6105 Acc: 0.8102\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 1 out of 11\n",
            "Epoch 5/99\n",
            "----------\n",
            "train Loss: 0.5150 Acc: 0.8407\n",
            "val Loss: 0.4215 Acc: 0.8757\n",
            "Current learning rate : 0.05000000\n",
            "Validation loss decreased (0.445124 --> 0.421546).  Saving model ...\n",
            "Epoch 6/99\n",
            "----------\n",
            "train Loss: 0.4593 Acc: 0.8587\n",
            "val Loss: 0.3564 Acc: 0.8961\n",
            "Current learning rate : 0.05000000\n",
            "Validation loss decreased (0.421546 --> 0.356403).  Saving model ...\n",
            "Epoch 7/99\n",
            "----------\n",
            "train Loss: 0.4429 Acc: 0.8647\n",
            "val Loss: 0.4389 Acc: 0.8893\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 1 out of 11\n",
            "Epoch 8/99\n",
            "----------\n",
            "train Loss: 0.4043 Acc: 0.8776\n",
            "val Loss: 0.3587 Acc: 0.9061\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 2 out of 11\n",
            "Epoch 9/99\n",
            "----------\n",
            "train Loss: 0.3502 Acc: 0.8919\n",
            "val Loss: 0.3233 Acc: 0.9085\n",
            "Current learning rate : 0.05000000\n",
            "Validation loss decreased (0.356403 --> 0.323302).  Saving model ...\n",
            "Epoch 10/99\n",
            "----------\n",
            "train Loss: 0.3474 Acc: 0.8904\n",
            "val Loss: 0.6673 Acc: 0.7851\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 1 out of 11\n",
            "Epoch 11/99\n",
            "----------\n",
            "train Loss: 0.3244 Acc: 0.9017\n",
            "val Loss: 0.3798 Acc: 0.8773\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 2 out of 11\n",
            "Epoch 12/99\n",
            "----------\n",
            "train Loss: 0.3188 Acc: 0.9028\n",
            "val Loss: 0.3308 Acc: 0.9041\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 3 out of 11\n",
            "Epoch 13/99\n",
            "----------\n",
            "train Loss: 0.3144 Acc: 0.9034\n",
            "val Loss: 0.2576 Acc: 0.9201\n",
            "Current learning rate : 0.05000000\n",
            "Validation loss decreased (0.323302 --> 0.257621).  Saving model ...\n",
            "Epoch 14/99\n",
            "----------\n",
            "train Loss: 0.2955 Acc: 0.9112\n",
            "val Loss: 0.2905 Acc: 0.9177\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 1 out of 11\n",
            "Epoch 15/99\n",
            "----------\n",
            "train Loss: 0.3036 Acc: 0.9083\n",
            "val Loss: 0.1664 Acc: 0.9537\n",
            "Current learning rate : 0.05000000\n",
            "Validation loss decreased (0.257621 --> 0.166389).  Saving model ...\n",
            "Epoch 16/99\n",
            "----------\n",
            "train Loss: 0.2894 Acc: 0.9128\n",
            "val Loss: 0.2042 Acc: 0.9385\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 1 out of 11\n",
            "Epoch 17/99\n",
            "----------\n",
            "train Loss: 0.2754 Acc: 0.9135\n",
            "val Loss: 0.2314 Acc: 0.9293\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 2 out of 11\n",
            "Epoch 18/99\n",
            "----------\n",
            "train Loss: 0.2469 Acc: 0.9269\n",
            "val Loss: 0.4042 Acc: 0.8761\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 3 out of 11\n",
            "Epoch 19/99\n",
            "----------\n",
            "train Loss: 0.2715 Acc: 0.9156\n",
            "val Loss: 0.2259 Acc: 0.9417\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 4 out of 11\n",
            "Epoch 20/99\n",
            "----------\n",
            "train Loss: 0.2511 Acc: 0.9278\n",
            "val Loss: 0.1453 Acc: 0.9624\n",
            "Current learning rate : 0.05000000\n",
            "Validation loss decreased (0.166389 --> 0.145310).  Saving model ...\n",
            "Epoch 21/99\n",
            "----------\n",
            "train Loss: 0.2468 Acc: 0.9289\n",
            "val Loss: 0.6477 Acc: 0.8190\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 1 out of 11\n",
            "Epoch 22/99\n",
            "----------\n",
            "train Loss: 0.2293 Acc: 0.9322\n",
            "val Loss: 0.2383 Acc: 0.9373\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 2 out of 11\n",
            "Epoch 23/99\n",
            "----------\n",
            "train Loss: 0.2298 Acc: 0.9338\n",
            "val Loss: 0.2116 Acc: 0.9365\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 3 out of 11\n",
            "Epoch 24/99\n",
            "----------\n",
            "train Loss: 0.2250 Acc: 0.9318\n",
            "val Loss: 0.5315 Acc: 0.8554\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 4 out of 11\n",
            "Epoch 25/99\n",
            "----------\n",
            "train Loss: 0.2495 Acc: 0.9229\n",
            "val Loss: 0.2669 Acc: 0.9301\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 5 out of 11\n",
            "Epoch 26/99\n",
            "----------\n",
            "train Loss: 0.2248 Acc: 0.9313\n",
            "val Loss: 0.3564 Acc: 0.8937\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 6 out of 11\n",
            "Epoch 27/99\n",
            "----------\n",
            "train Loss: 0.2371 Acc: 0.9277\n",
            "val Loss: 0.2366 Acc: 0.9285\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 7 out of 11\n",
            "Epoch 28/99\n",
            "----------\n",
            "train Loss: 0.2175 Acc: 0.9359\n",
            "val Loss: 0.1138 Acc: 0.9724\n",
            "Current learning rate : 0.05000000\n",
            "Validation loss decreased (0.145310 --> 0.113753).  Saving model ...\n",
            "Epoch 29/99\n",
            "----------\n",
            "train Loss: 0.2017 Acc: 0.9403\n",
            "val Loss: 1.7456 Acc: 0.6864\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 1 out of 11\n",
            "Epoch 30/99\n",
            "----------\n",
            "train Loss: 0.2312 Acc: 0.9342\n",
            "val Loss: 0.1697 Acc: 0.9533\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 2 out of 11\n",
            "Epoch 31/99\n",
            "----------\n",
            "train Loss: 0.2225 Acc: 0.9356\n",
            "val Loss: 0.3778 Acc: 0.9017\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 3 out of 11\n",
            "Epoch 32/99\n",
            "----------\n",
            "train Loss: 0.2271 Acc: 0.9327\n",
            "val Loss: 0.3808 Acc: 0.8993\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 4 out of 11\n",
            "Epoch 33/99\n",
            "----------\n",
            "train Loss: 0.2251 Acc: 0.9315\n",
            "val Loss: 0.3814 Acc: 0.9029\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 5 out of 11\n",
            "Epoch 34/99\n",
            "----------\n",
            "train Loss: 0.2093 Acc: 0.9370\n",
            "val Loss: 0.3932 Acc: 0.9021\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 6 out of 11\n",
            "Epoch 35/99\n",
            "----------\n",
            "train Loss: 0.2240 Acc: 0.9327\n",
            "val Loss: 0.2012 Acc: 0.9461\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 7 out of 11\n",
            "Epoch 36/99\n",
            "----------\n",
            "train Loss: 0.2052 Acc: 0.9389\n",
            "val Loss: 0.8329 Acc: 0.8082\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 8 out of 11\n",
            "Epoch 37/99\n",
            "----------\n",
            "train Loss: 0.2189 Acc: 0.9343\n",
            "val Loss: 0.1302 Acc: 0.9720\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 9 out of 11\n",
            "Epoch 38/99\n",
            "----------\n",
            "train Loss: 0.2027 Acc: 0.9390\n",
            "val Loss: 0.3752 Acc: 0.8893\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 10 out of 11\n",
            "Epoch 39/99\n",
            "----------\n",
            "train Loss: 0.2065 Acc: 0.9383\n",
            "val Loss: 0.1852 Acc: 0.9477\n",
            "Current learning rate : 0.05000000\n",
            "EarlyStopping counter: 11 out of 11\n",
            "Early stopping\n",
            "Training complete in 115m 41s\n",
            "Best val Acc: 0.972433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwXg15D8h3ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_ft, '/content/drive/My Drive/Colab Notebooks/pyTorch/ef_model_ft.pt')\n",
        "torch.save(model, '/content/drive/My Drive/Colab Notebooks/pyTorch/ef_model.pt')\n",
        "torch.save(model_ft.state_dict(), '/content/drive/My Drive/Colab Notebooks/pyTorch/ef_model_ft_state_dict.pt')\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/Colab Notebooks/pyTorch/ef_model_state_dict.pt')\n"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}